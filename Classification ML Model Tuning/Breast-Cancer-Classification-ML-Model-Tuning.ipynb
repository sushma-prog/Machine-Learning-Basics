{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28daeb3b-eda5-4abb-88ec-06235c77612b",
   "metadata": {},
   "source": [
    "# üî∑ Part A: Train and Test ML Models\n",
    "\n",
    "We‚Äôll learn:\n",
    "\n",
    "- Why we split data into train and test sets\n",
    "\n",
    "- Use train_test_split() from sklearn.model_selection\n",
    "\n",
    "- Understand random_state and why it matters\n",
    "\n",
    "- Train a model on training data\n",
    "\n",
    "- Test the model on test data\n",
    "\n",
    "- Calculate accuracy (and later precision/recall/F1 if needed)\n",
    "\n",
    "- Understand what data leakage is and how to avoid it\n",
    "\n",
    "# üî∑ Part B: Model Validation Techniques\n",
    "\n",
    "We‚Äôll cover slightly more advanced validation tools:\n",
    "\n",
    "- k-Fold Cross-Validation\n",
    "\n",
    "Use cross_val_score() to train/test model multiple times\n",
    "\n",
    "- GridSearchCV (Intro)\n",
    "\n",
    "Automatically try different model parameters and find the best\n",
    "\n",
    "- classification_report\n",
    "\n",
    "See precision, recall, F1-score all at once, class-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef30974-a609-42de-b7b0-565eadc52184",
   "metadata": {},
   "source": [
    "## üî∑ Part A: Train and Test ML Models\n",
    "\n",
    "### üß† Why Split the Data?\n",
    "\n",
    "When training an ML model, we want to test if it can predict on unseen data.\n",
    "\n",
    "So we divide our data into:\n",
    "\n",
    "- Training Set (e.g., 70%): The model learns from this.\n",
    "\n",
    "- Test Set (e.g., 30%): Used only to evaluate how well the model performs on new data.\n",
    "\n",
    "This avoids overfitting, which happens when the model memorizes the training data instead of learning patterns.\n",
    "\n",
    "### üß† Understand random_state and why it matters\n",
    "\n",
    "When we split data using train_test_split, it selects random samples for training and testing.\n",
    "\n",
    "- If you don‚Äôt use random_state, the split will be different each time you run the code.\n",
    "\n",
    "- If you set random_state to a number (like 42), you make the randomness consistent and reproducible.\n",
    "\n",
    "üìå This is important for reproducibility. For example, during debugging, testing, or sharing notebooks with others, we want the results to be exactly the same every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f212ea-2ec5-4358-ab71-27148e70c5ed",
   "metadata": {},
   "source": [
    "### üîç Breast Cancer Dataset (Overview)\n",
    "\n",
    "- üéØ **Goal**: Predict if a tumor is malignant (cancerous) or benign (non-cancerous)\n",
    "\n",
    "- üî¢ **Target**: Binary (0 = malignant, 1 = benign)\n",
    "\n",
    "- üìä **Features**: 30 numerical features (e.g., mean radius, texture, perimeter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f0ca9-60bb-4415-919e-17f05434d459",
   "metadata": {},
   "source": [
    "**üî∑ Step 1: Import Libraries and Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a409ef22-0f52-4ee3-9d7c-f336b75b8db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load_breast_cancer ‚Äì loads the dataset\n",
    "# train_test_split ‚Äì used to split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7718aa2-df1d-45e3-93cc-67f342a4ac44",
   "metadata": {},
   "source": [
    "**üî∑ Step 2: Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398d90b2-bddb-4e6c-afbb-d11320c400d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the dataset\n",
    "data = load_breast_cancer()\n",
    "x = data.data # 30 features (inputs)\n",
    "y = data.target # Target labels: 0 (malignant), 1 (benign)\n",
    "\n",
    "# X: feature matrix of shape (569, 30)\n",
    "# y: label vector of shape (569,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770a97a-a621-426b-a14d-199845191992",
   "metadata": {},
   "source": [
    "**üî∑ Step 3: Split into Train/Test Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f0bc95-22f0-4412-be8c-1669740fff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split data (70% train, 30% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# test_size=0.3: 30% for testing, 70% for training\n",
    "# random_state=42: keeps results consistent every time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b7e07-d77f-4ef9-becd-03a489421330",
   "metadata": {},
   "source": [
    "**üî∑ Step 4: Confirm the Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaed1110-4f1a-45d5-aed7-ff7ee55cb681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Shape: (398, 30)\n",
      "x_test Shape: (171, 30)\n",
      "y_train Shape: (398,)\n",
      "y_test Shape: (171,)\n"
     ]
    }
   ],
   "source": [
    "# 4. Check the shape of each split\n",
    "print(\"x_train Shape:\", x_train.shape)\n",
    "print(\"x_test Shape:\", x_test.shape)\n",
    "print(\"y_train Shape:\", y_train.shape)\n",
    "print(\"y_test Shape:\", y_test.shape)\n",
    "\n",
    "# This confirms that data was split correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a590dc-36cf-4c60-b769-a3c5fe676b70",
   "metadata": {},
   "source": [
    "**‚úÖ Step 5: Train a Model on Training Data**\n",
    "\n",
    "We‚Äôll use the RandomForestClassifier here ‚Äî a very good and reliable model for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9267764-e00c-4a8c-b9cb-ff6ab1ba759d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Train a Model\n",
    "from sklearn.ensemble import RandomForestClassifier #RandomForestClassifier: A tree-based ensemble model that combines many decision trees to make a stronger model.\n",
    "\n",
    "# Create the model\n",
    "rf_model = RandomForestClassifier(random_state=42) #random_state=42: Ensures results are reproducible ‚Äî you'll get the same model every time.\n",
    "\n",
    "# Train (fit) the model on training data\n",
    "rf_model.fit(x_train, y_train) #.fit(x_train, y_train): Trains the model using the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a352626-c514-4dde-ab09-b35ab540d69f",
   "metadata": {},
   "source": [
    "**‚úÖ Step 6: Test the Model on Test Data and Calculate Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "139ff0f3-cc5d-405e-bf21-e9e82fc0decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Make Predictions and Evaluate Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf_model.predict(x_test) #y_pred = rf_model.predict(x_test): Makes predictions for the unseen test data.\n",
    "\n",
    "# Compare predicted vs actual\n",
    "accuracy = accuracy_score(y_test, y_pred) #accuracy_score(y_test, y_pred): Compares predicted labels to actual labels and returns the percentage of correct predictions.\n",
    "\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c7b50-9530-43ef-ae1a-fcc4d7f54c98",
   "metadata": {},
   "source": [
    "**Test Accuracy: 0.97**\n",
    "\n",
    "üìå This means 97% of the predictions on the test set were correct.\n",
    "Very high accuracy ‚Äî shows the model is performing very well overall.\n",
    "\n",
    "### ‚úÖ When do we need more than just accuracy?\n",
    "\n",
    "**Accuracy is enough:**\n",
    "\n",
    "- When the dataset is balanced (roughly equal number of each class)\n",
    "\n",
    "- When all errors matter equally\n",
    "\n",
    "‚úÖ For example, Breast Cancer dataset is fairly balanced, so accuracy alone gives a decent idea of performance.\n",
    "\n",
    "**But... Accuracy is not enough:**\n",
    "    \n",
    "We also calculate Precision, Recall, and F1-score when:\n",
    "\n",
    "- The dataset is imbalanced (e.g., 90% Class A, 10% Class B)\n",
    "\n",
    "- We care about certain types of errors more than others\n",
    "e.g., Missing a cancer case (false negative) is worse than a false alarm (false positive)\n",
    "\n",
    "That‚Äôs why we include them for better model insight even on balanced data ‚Äî it's best practice. ‚úÖ\n",
    "\n",
    "### ‚úÖ Let's add Precision, Recall, and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2c4372-756a-47de-a93b-b2db3a0d1054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.98      0.94      0.96        63\n",
      "      Benign       0.96      0.99      0.98       108\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report # classification_report: Combines precision, recall, F1-score, and support in one clean summary.\n",
    "\n",
    "# Generate precision, recall, f1-score, and support\n",
    "report = classification_report(y_test, y_pred, target_names=[\"Malignant\", \"Benign\"]) # target_names: Names for class 0 and 1 ‚Äî in breast cancer data: 0 = Malignant (dangerous), 1 = Benign (not dangerous)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf2dc9-94db-44d0-b27f-86ea175c7c74",
   "metadata": {},
   "source": [
    " \n",
    "### üßæ Let‚Äôs decode your **Classification Report:**\n",
    "\n",
    "| Class             | Precision | Recall | F1-score | Support |\n",
    "| ----------------- | --------- | ------ | -------- | ------- |\n",
    "| **Malignant (0)** | 0.98      | 0.94   | 0.96     | 63      |\n",
    "| **Benign (1)**    | 0.96      | 0.99   | 0.98     | 108     |\n",
    "\n",
    "### What each part means:\n",
    "\n",
    "**üîπ Precision**\n",
    "\n",
    "***- Malignant: 0.98***\n",
    "\n",
    "Out of all the times model predicted \"malignant\", 98% were actually malignant.\n",
    "Great for reducing false positives (labeling someone as sick when they‚Äôre not).\n",
    "\n",
    "***- Benign: 0.96 ‚Äî Also great!***\n",
    "\n",
    "**üîπ Recall**\n",
    "\n",
    "***- Malignant: 0.94***\n",
    "\n",
    "Out of all the actual malignant cases, it caught 94%.\n",
    "This is very important in medical problems ‚Äî you don‚Äôt want to miss a real cancer case.\n",
    "\n",
    "***- Benign: 0.99 ‚Äî Excellent!***\n",
    "\n",
    "**üîπ F1-score**\n",
    "\n",
    "This balances precision and recall.\n",
    "\n",
    "***- Malignant: 0.96***\n",
    "\n",
    "***- Benign: 0.98***\n",
    "\n",
    "Both are high ‚Äî meaning your model is very balanced and strong.\n",
    "\n",
    "**üîç What are:**\n",
    "\n",
    "***üìä Macro avg***\n",
    "\n",
    "Just the average of all classes (treats all classes equally).\n",
    "\n",
    "***üìä Weighted avg***\n",
    "\n",
    "Average, but takes class frequency into account (Benign has more examples than Malignant).\n",
    "\n",
    "### ‚úÖ Summary (in simple terms):\n",
    "\n",
    "- Model is doing a great job at both detecting cancer and avoiding false alarms.\n",
    "\n",
    "- Recall for malignant is 94%, which is strong ‚Äî but in critical fields like cancer detection, we often want even higher recall (maybe tune it later using GridSearchCV or better preprocessing).\n",
    "\n",
    "- You're now using complete evaluation, not just accuracy ‚Äî this makes your analysis professional and trustworthy üíº‚úîÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338511d-263e-4c2a-9722-e9c6ec406179",
   "metadata": {},
   "source": [
    "### üõë Part A (Final Step): Understanding and Preventing Data Leakage\n",
    "\n",
    "**üîç What is Data Leakage?**\n",
    "\n",
    "Data Leakage happens when information from outside the training dataset (usually the test set or future data) is used to train the model.\n",
    "\n",
    "This gives your model an unfair advantage ‚Äî like cheating in an exam!\n",
    "\n",
    "**üö® Why is it bad?**\n",
    "\n",
    "- The model looks like it performs extremely well during training.\n",
    "\n",
    "- But when it's deployed on real unseen data, it fails badly.\n",
    "\n",
    "- It gives you a false sense of accuracy.\n",
    "\n",
    "**üí° Real-Life Example of Data Leakage:**\n",
    "\n",
    "Imagine you‚Äôre predicting if a patient has cancer.\n",
    "\n",
    "- You accidentally include a column like \"biopsy_result\" in the training features ‚Äî which already reveals if the patient has cancer.\n",
    "\n",
    "- Model learns this shortcut and gets 100% accuracy.\n",
    "\n",
    "- But in real hospital use, you won‚Äôt have that result before prediction, so your model fails.\n",
    "\n",
    "**‚úÖ Common Causes of Data Leakage:**\n",
    "\n",
    "| Mistake                                                        | Why it leaks                    |\n",
    "| -------------------------------------------------------------- | ------------------------------- |\n",
    "| Using **test data** during training                            | Model \"sees\" answers early      |\n",
    "| Applying **scaling or encoding** to full data before splitting | Info from test leaks into train |\n",
    "| Including **target-related features**                          | Model learns from future        |\n",
    "\n",
    "**‚úÖ How to Avoid Data Leakage:**\n",
    "\n",
    "- Always split your data first (did this ‚úÖ).\n",
    "\n",
    "- Only fit scalers/encoders on training data, then apply to test data.\n",
    "\n",
    "- Be careful with feature selection ‚Äî don‚Äôt include future or label-based columns.\n",
    "\n",
    "- In pipelines (learn later), scikit-learn helps prevent leakage automatically.\n",
    "\n",
    "**‚úÖ So did we prevent leakage today?**\n",
    "\n",
    "Yes! ‚úÖ\n",
    "\n",
    "Let‚Äôs double-check what we did:\n",
    "\n",
    "| Step                                           | Safe? | Why?                       |\n",
    "| ---------------------------------------------- | ----- | -------------------------- |\n",
    "| Used `train_test_split()` **before training**  | ‚úÖ     | Prevented future info leak |\n",
    "| Didn‚Äôt apply scaling or encoding yet           | ‚úÖ     | No leakage risk            |\n",
    "| Trained model only on `x_train`, not full data | ‚úÖ     | Proper practice            |\n",
    "| Evaluated on untouched `x_test`                | ‚úÖ     | Realistic test             |\n",
    "\n",
    "Perfect!\n",
    "\n",
    "**üéØ Summary:**\n",
    "\n",
    "- Data leakage ruins your model‚Äôs real-world usefulness.\n",
    "\n",
    "- But by following good practices like splitting early, training only on training data, and avoiding future info, you keep your models honest and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d60f8-8e87-4f41-9fdd-1e4c81528119",
   "metadata": {},
   "source": [
    "## üî∑ Part B: Model Validation Techniques\n",
    "\n",
    "**‚úÖ Step 1: k-Fold Cross-Validation using cross_val_score()**\n",
    "\n",
    "- What it is: Instead of training on 1 fixed train-test split, the model is trained/tested on k different folds.\n",
    "\n",
    "- Why: It gives you a more reliable estimate of model performance.\n",
    "\n",
    "**‚úÖ Step 2: GridSearchCV (Intro)**\n",
    "\n",
    "- What it does: Tries many combinations of model parameters automatically.\n",
    "\n",
    "- Why: Helps you tune hyperparameters and find the best version of your model.\n",
    "\n",
    "**‚úÖ Step 3: classification_report**\n",
    "\n",
    "- We already used this once üëç\n",
    "\n",
    "- We'll review how it shows precision, recall, F1-score, and support class-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f8905-7c26-49f4-bcd5-c536ba91c881",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 1: k-Fold Cross-Validation using cross_val_score()\n",
    "\n",
    "**üîç What is k-Fold Cross-Validation?**\n",
    "\n",
    "Normally, we split data once into training and test sets. But that gives performance on just one split.\n",
    "\n",
    "In k-Fold Cross-Validation, the data is split into k equal parts (‚Äúfolds‚Äù):\n",
    "\n",
    "- Train the model on k-1 folds\n",
    "\n",
    "- Test on the remaining 1 fold\n",
    "\n",
    "- Repeat the process k times, each time using a different fold as test set\n",
    "\n",
    "- Take the average score\n",
    "\n",
    "‚úÖ This gives a better estimate of how the model will perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62068752-6f87-4a73-bedb-3e5968cc89b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores (Each Fold): [0.92105263 0.93859649 0.98245614 0.96491228 0.97345133]\n",
      "Average Cross-Validation Score: 0.9560937742586555\n"
     ]
    }
   ],
   "source": [
    "# 1. Import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score #from sklearn.model_selection import cross_val_score ‚Üí Imports the function that does k-fold cross-validation for you.\n",
    "from sklearn.ensemble import RandomForestClassifier # already did this before\n",
    "\n",
    "# 2. Create the model again\n",
    "model = RandomForestClassifier(random_state=42) # already did this before\n",
    "# model = RandomForestClassifier(random_state=42) ‚Üí You define the model you want to validate.\n",
    "\n",
    "# 3. Apply k-fold cross-validation (default k=5)\n",
    "# cross_val_score does 5-fold cross-validation by default\n",
    "cv_scores = cross_val_score(model, x, y, cv=5) # full data (x, y), not just train or test\n",
    "# cross_val_score(model, x, y, cv=5)\n",
    "# ‚Üí Tells scikit-learn to:\n",
    "# - Use the model stored in model veriable i.e. RandomForestClassifier\n",
    "# - Use the whole dataset x and y\n",
    "# - Split it into 5 parts (folds)\n",
    "# - Train/test 5 times\n",
    "# - Return the score (accuracy) for each fold\n",
    "\n",
    "# 4. Print individual scores and average score\n",
    "print(\"Cross-Validation Scores (Each Fold):\", cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", cv_scores.mean())\n",
    "# cv_scores.mean()\n",
    "# ‚Üí Calculates the average accuracy across all 5 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432dcd9-093a-4196-ab7c-d6f7abfad40d",
   "metadata": {},
   "source": [
    "### ‚úÖ What We‚Äôve Achieved Just Now:\n",
    "\n",
    "**üîÅ k-Fold Cross-Validation Recap:**\n",
    "\n",
    "- It splits the entire dataset into k parts (you chose cv=5 ‚Üí 5 parts).\n",
    "\n",
    "- The model is trained and tested 5 times, each time using a different fold for testing.\n",
    "\n",
    "- This gives a better, more reliable performance estimate than just one train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f16d23-69a6-4827-a1c9-773acb816834",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 3: GridSearchCV \n",
    "\n",
    "**üî∑ What is GridSearchCV?**\n",
    "\n",
    "GridSearchCV helps us:\n",
    "\n",
    "- Try out different values for hyperparameters (like number of trees, max depth, etc.)\n",
    "\n",
    "- Evaluate each combination using cross-validation\n",
    "\n",
    "- Pick the best model based on performance (like highest accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0da4a5-16b0-47ae-948f-50bf54e69102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Best Score: 0.9631268436578171\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Import necessary tools\n",
    "from sklearn.model_selection import GridSearchCV # GridSearchCV: This is the main tool we‚Äôll use to automatically try different parameter values and find the best model\n",
    "from sklearn.ensemble import RandomForestClassifier # The model we want to tune (a powerful ensemble of decision trees).\n",
    "\n",
    "#step 2: Create the model\n",
    "model = RandomForestClassifier(random_state=42) #random_state=42 ensures we get the same result every time we run it (for reproducibility).\n",
    "\n",
    "#Step 3: Define the grid of parameters\n",
    "# We are giving multiple values to test for each hyperparameter:\n",
    "param_grid = {\n",
    "    \"n_estimators\" : [10,50,100], #'n_estimators': Try models with 10, 50, and 100 trees.\n",
    "    \"max_depth\" : [None,5,10], # Try no limit, depth 5, and depth 10 \n",
    "    \"min_samples_split\" : [2,5], # Try splitting a node at 2 or 5 samples\n",
    "} # We‚Äôre giving GridSearchCV 3 options for n_estimators, 3 for max_depth, and 2 for min_samples_split ‚Äî so it will try 3 √ó 3 √ó 2 = 18 combinations of these settings.\n",
    "\n",
    "#Step 4: Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, #estimator=model: The model to tune. (model=RandomForestClassifier(random_state=42)).\n",
    "    param_grid=param_grid, #param_grid=...: The dictionary of parameters to try that we made earlier.\n",
    "    cv=5, #cv=5: Perform 5-fold cross-validation.\n",
    "    scoring=\"accuracy\", #scoring='accuracy': Evaluate how accurate the model is for each combination.\n",
    ")\n",
    "# What this tells the computer:\n",
    "# Use the RandomForestClassifier as our model.\n",
    "# Try every combination from param_grid.\n",
    "# For each combination, perform 5-fold cross-validation.\n",
    "# Use accuracy to evaluate how good the model is.\n",
    "\n",
    "#Step 5: Fit the model\n",
    "grid_search.fit(x,y) \n",
    "# It trains and evaluates the model 18 times (once for each parameter combination), using 5-fold cross-validation for each ‚Äî so 90 model fits in total.\n",
    "# It remembers which combination gave the best accuracy.\n",
    "\n",
    "#Step 6: Print the results\n",
    "print(\"Best Parameters:\", grid_search.best_params_) # .best_params_: Show which combination gave the best results.\n",
    "print(\"Best Score:\", grid_search.best_score_) # .best_score_: Show the average accuracy from cross-validation for the best combination.\n",
    "# Tells us which combination of parameters gave the best result.\n",
    "# Shows the best accuracy score achieved during the search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c71b36-5bf8-409a-be8c-72590a0a8b2f",
   "metadata": {},
   "source": [
    "**‚úÖ What This Means:**\n",
    "\n",
    "1)n_estimators = 50\n",
    "\n",
    "- Your model performs best when it builds a forest of 50 trees.\n",
    "\n",
    "2)max_depth = None\n",
    "\n",
    "- This allows each tree to grow fully (no depth limit). This likely helps capture more patterns in the data.\n",
    "\n",
    "3)min_samples_split = 5\n",
    "\n",
    "- A node must have at least 5 samples to be split further. This helps prevent overfitting.\n",
    "\n",
    "4)Best Score ‚âà 96.3%\n",
    "\n",
    "- This is the average accuracy across all 5 folds, which means your model generalizes well.\n",
    "\n",
    "**üß† Why GridSearchCV Matters:**\n",
    "\n",
    "- You tried 18 different combinations (3√ó3√ó2) and picked the one with the best balance of performance.\n",
    "\n",
    "- This removes the guesswork and helps build the most reliable and optimized model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35650ed5-283d-45e5-9052-82a51c37ec2c",
   "metadata": {},
   "source": [
    "### ‚úÖ Step 4: classification_report\n",
    "\n",
    "**üß† Why are we doing this?**\n",
    "\n",
    "***‚úÖ Goal:***\n",
    "\n",
    "Now that we‚Äôve fine-tuned our model using GridSearchCV, we want to evaluate the final best-performing model using detailed classification metrics:\n",
    "\n",
    "- Precision ‚Äì Out of all the positive predictions, how many were correct?\n",
    "\n",
    "- Recall ‚Äì Out of all actual positives, how many were correctly predicted?\n",
    "\n",
    "- F1-score ‚Äì Balance between precision and recall.\n",
    "\n",
    "- Support ‚Äì Number of true instances for each class.\n",
    "\n",
    "This gives us a complete picture of how well our optimized model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34ea82e1-8578-4772-8809-05480feea90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Final Tuned Model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Malignant       0.94      0.98      0.96        60\n",
      "      Benign       0.99      0.96      0.98       111\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.96      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Use the best model selected by GridSearchCV\n",
    "best_model = grid_search.best_estimator_  #grid_search.best_estimator_\tRetrieves the best model found during GridSearchCV tuning\n",
    "\n",
    "# Step 2: Predict on the test set\n",
    "y_pred_best = best_model.predict(x_test) #.predict(x_test)\tUses the best model to make predictions on the test set\n",
    "\n",
    "# Step 3: Generate a detailed classification report\n",
    "report = classification_report(\n",
    "    y_pred,\n",
    "    y_pred_best,\n",
    "    target_names=[\"Malignant\", \"Benign\"]\n",
    ") #classification_report()\tCalculates precision, recall, F1-score, and support for each class\n",
    "\n",
    "print(\"Classification Report for Final Tuned Model:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd0349-b478-4983-b9ad-a094c8894426",
   "metadata": {},
   "source": [
    "**üí° Key Takeaways:**\n",
    "    \n",
    "- Malignant (Cancerous):\n",
    "\n",
    "  Precision: 94% ‚Äì Out of all predicted \"Malignant\", 94% were correct.\n",
    "\n",
    "  Recall: 98% ‚Äì Out of all actual \"Malignant\", 98% were caught. üî•\n",
    "\n",
    "  F1-score: Balanced and high at 96%.\n",
    "\n",
    "- Benign (Non-Cancerous):\n",
    "\n",
    "  Precision: 99% ‚Äì Very few false positives.\n",
    "\n",
    "  Recall: 96% ‚Äì Almost all actual benign cases were correctly detected.\n",
    "\n",
    "  F1-score: 98% ‚Äì Very strong.\n",
    "\n",
    "- Macro avg treats both classes equally.\n",
    "\n",
    "- Weighted avg accounts for class imbalance (more benign cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55fb6a5-7dbc-43b4-9b3e-29af28a4f05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
