{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a3b157-e6ae-4bcb-8149-137261ee4e50",
   "metadata": {},
   "source": [
    "## üî∑ Step 1: Load and Understand the Dataset\n",
    "\n",
    "### ‚úÖ What we‚Äôll do in this step:\n",
    "\n",
    "Load the CSV using pandas\n",
    "\n",
    "View first few rows\n",
    "\n",
    "Check shape (rows √ó columns)\n",
    "\n",
    "See data types and missing values\n",
    "\n",
    "View basic stats (mean, std, etc.)\n",
    "\n",
    "Identify features vs target (Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69a6eb0f-b02e-4246-8e64-c97870414262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:    Index                                              Title  \\\n",
      "0      0  1 BHK Ready to Occupy Flat for sale in Srushti...   \n",
      "1      1  2 BHK Ready to Occupy Flat for sale in Dosti V...   \n",
      "2      2  2 BHK Ready to Occupy Flat for sale in Sunrise...   \n",
      "3      3        1 BHK Ready to Occupy Flat for sale Kasheli   \n",
      "4      4  2 BHK Ready to Occupy Flat for sale in TenX Ha...   \n",
      "\n",
      "                                         Description Amount(in rupees)  \\\n",
      "0  Bhiwandi, Thane has an attractive 1 BHK Flat f...           42 Lac    \n",
      "1  One can find this stunning 2 BHK flat for sale...           98 Lac    \n",
      "2  Up for immediate sale is a 2 BHK apartment in ...          1.40 Cr    \n",
      "3  This beautiful 1 BHK Flat is available for sal...           25 Lac    \n",
      "4  This lovely 2 BHK Flat in Pokhran Road, Thane ...          1.60 Cr    \n",
      "\n",
      "   Price (in rupees) location Carpet Area         Status         Floor  \\\n",
      "0             6000.0    thane    500 sqft  Ready to Move  10 out of 11   \n",
      "1            13799.0    thane    473 sqft  Ready to Move   3 out of 22   \n",
      "2            17500.0    thane    779 sqft  Ready to Move  10 out of 29   \n",
      "3                NaN    thane    530 sqft  Ready to Move    1 out of 3   \n",
      "4            18824.0    thane    635 sqft  Ready to Move  20 out of 42   \n",
      "\n",
      "  Transaction  ... facing             overlooking  \\\n",
      "0      Resale  ...    NaN                     NaN   \n",
      "1      Resale  ...   East             Garden/Park   \n",
      "2      Resale  ...   East             Garden/Park   \n",
      "3      Resale  ...    NaN                     NaN   \n",
      "4      Resale  ...   West  Garden/Park, Main Road   \n",
      "\n",
      "                               Society Bathroom Balcony Car Parking  \\\n",
      "0  Srushti Siddhi Mangal Murti Complex        1       2         NaN   \n",
      "1                          Dosti Vihar        2     NaN      1 Open   \n",
      "2                 Sunrise by Kalpataru        2     NaN   1 Covered   \n",
      "3                                  NaN        1       1         NaN   \n",
      "4          TenX Habitat Raymond Realty        2     NaN   1 Covered   \n",
      "\n",
      "              Ownership Super Area Dimensions  Plot Area  \n",
      "0                   NaN        NaN        NaN        NaN  \n",
      "1              Freehold        NaN        NaN        NaN  \n",
      "2              Freehold        NaN        NaN        NaN  \n",
      "3                   NaN        NaN        NaN        NaN  \n",
      "4  Co-operative Society        NaN        NaN        NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      " Dataset Shape (rows,columns): (187531, 21)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187531 entries, 0 to 187530\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Index              187531 non-null  int64  \n",
      " 1   Title              187531 non-null  object \n",
      " 2   Description        184508 non-null  object \n",
      " 3   Amount(in rupees)  187531 non-null  object \n",
      " 4   Price (in rupees)  169866 non-null  float64\n",
      " 5   location           187531 non-null  object \n",
      " 6   Carpet Area        106858 non-null  object \n",
      " 7   Status             186916 non-null  object \n",
      " 8   Floor              180454 non-null  object \n",
      " 9   Transaction        187448 non-null  object \n",
      " 10  Furnishing         184634 non-null  object \n",
      " 11  facing             117298 non-null  object \n",
      " 12  overlooking        106095 non-null  object \n",
      " 13  Society            77853 non-null   object \n",
      " 14  Bathroom           186703 non-null  object \n",
      " 15  Balcony            138596 non-null  object \n",
      " 16  Car Parking        84174 non-null   object \n",
      " 17  Ownership          122014 non-null  object \n",
      " 18  Super Area         79846 non-null   object \n",
      " 19  Dimensions         0 non-null       float64\n",
      " 20  Plot Area          0 non-null       float64\n",
      "dtypes: float64(3), int64(1), object(17)\n",
      "memory usage: 30.0+ MB\n",
      "\n",
      " Dataset Info:  None\n",
      "\n",
      " Summary Statistics:                  Index                                              Title  \\\n",
      "count   187531.000000                                             187531   \n",
      "unique            NaN                                              32446   \n",
      "top               NaN  2 BHK Ready to Occupy Flat for sale in Divyasr...   \n",
      "freq              NaN                                               2106   \n",
      "mean     93765.000000                                                NaN   \n",
      "std      54135.681003                                                NaN   \n",
      "min          0.000000                                                NaN   \n",
      "25%      46882.500000                                                NaN   \n",
      "50%      93765.000000                                                NaN   \n",
      "75%     140647.500000                                                NaN   \n",
      "max     187530.000000                                                NaN   \n",
      "\n",
      "                                              Description Amount(in rupees)  \\\n",
      "count                                              184508            187531   \n",
      "unique                                              65634              1561   \n",
      "top     Multistorey apartment is available for sale. I...    Call for Price   \n",
      "freq                                                 2732              9684   \n",
      "mean                                                  NaN               NaN   \n",
      "std                                                   NaN               NaN   \n",
      "min                                                   NaN               NaN   \n",
      "25%                                                   NaN               NaN   \n",
      "50%                                                   NaN               NaN   \n",
      "75%                                                   NaN               NaN   \n",
      "max                                                   NaN               NaN   \n",
      "\n",
      "        Price (in rupees)   location Carpet Area         Status       Floor  \\\n",
      "count        1.698660e+05     187531      106858         186916      180454   \n",
      "unique                NaN         81        2758              1         947   \n",
      "top                   NaN  new-delhi   1000 sqft  Ready to Move  2 out of 4   \n",
      "freq                  NaN      27599        5285         186916       12433   \n",
      "mean         7.583772e+03        NaN         NaN            NaN         NaN   \n",
      "std          2.724171e+04        NaN         NaN            NaN         NaN   \n",
      "min          0.000000e+00        NaN         NaN            NaN         NaN   \n",
      "25%          4.297000e+03        NaN         NaN            NaN         NaN   \n",
      "50%          6.034000e+03        NaN         NaN            NaN         NaN   \n",
      "75%          9.450000e+03        NaN         NaN            NaN         NaN   \n",
      "max          6.700000e+06        NaN         NaN            NaN         NaN   \n",
      "\n",
      "       Transaction  ...  facing overlooking           Society Bathroom  \\\n",
      "count       187448  ...  117298      106095             77853   186703   \n",
      "unique           4  ...       8          19             10376       11   \n",
      "top         Resale  ...    East   Main Road  Hamdam Apartment        2   \n",
      "freq        144172  ...   54741       32193              1648    93007   \n",
      "mean           NaN  ...     NaN         NaN               NaN      NaN   \n",
      "std            NaN  ...     NaN         NaN               NaN      NaN   \n",
      "min            NaN  ...     NaN         NaN               NaN      NaN   \n",
      "25%            NaN  ...     NaN         NaN               NaN      NaN   \n",
      "50%            NaN  ...     NaN         NaN               NaN      NaN   \n",
      "75%            NaN  ...     NaN         NaN               NaN      NaN   \n",
      "max            NaN  ...     NaN         NaN               NaN      NaN   \n",
      "\n",
      "       Balcony Car Parking Ownership Super Area Dimensions  Plot Area  \n",
      "count   138596       84174    122014      79846        0.0        0.0  \n",
      "unique      11         229         4       2976        NaN        NaN  \n",
      "top          2   1 Covered  Freehold  1100 sqft        NaN        NaN  \n",
      "freq     51809       38754    112229       2599        NaN        NaN  \n",
      "mean       NaN         NaN       NaN        NaN        NaN        NaN  \n",
      "std        NaN         NaN       NaN        NaN        NaN        NaN  \n",
      "min        NaN         NaN       NaN        NaN        NaN        NaN  \n",
      "25%        NaN         NaN       NaN        NaN        NaN        NaN  \n",
      "50%        NaN         NaN       NaN        NaN        NaN        NaN  \n",
      "75%        NaN         NaN       NaN        NaN        NaN        NaN  \n",
      "max        NaN         NaN       NaN        NaN        NaN        NaN  \n",
      "\n",
      "[11 rows x 21 columns]\n",
      "\n",
      " Missing Values per Column Index                     0\n",
      "Title                     0\n",
      "Description            3023\n",
      "Amount(in rupees)         0\n",
      "Price (in rupees)     17665\n",
      "location                  0\n",
      "Carpet Area           80673\n",
      "Status                  615\n",
      "Floor                  7077\n",
      "Transaction              83\n",
      "Furnishing             2897\n",
      "facing                70233\n",
      "overlooking           81436\n",
      "Society              109678\n",
      "Bathroom                828\n",
      "Balcony               48935\n",
      "Car Parking          103357\n",
      "Ownership             65517\n",
      "Super Area           107685\n",
      "Dimensions           187531\n",
      "Plot Area            187531\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the dataset\n",
    "df = pd.read_csv(\"house_prices.csv\")\n",
    "\n",
    "# 2. Display first 5 row\n",
    "print(\"First 5 rows of the dataset:\", df.head())\n",
    "\n",
    "# 3. Shape of the dataset\n",
    "print(\"\\n Dataset Shape (rows,columns):\", df.shape)\n",
    "\n",
    "# 4. Info about data types and missing values\n",
    "print(\"\\n Dataset Info: \", df.info())\n",
    "\n",
    "# 5. Summary statistics\n",
    "print(\"\\n Summary Statistics: \", df.describe(include=\"all\"))\n",
    "\n",
    "# 6. Count missing values per column\n",
    "print(\"\\n Missing Values per Column\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd071c-8bd3-4d2a-8d2b-3da0afec8305",
   "metadata": {},
   "source": [
    "### üß†  Key Insights from Dataset Overview\n",
    "\n",
    "**üîπ 1. Dataset Shape and Size**\n",
    "    \n",
    "- Rows (properties): 187,531\n",
    "\n",
    "- Columns (features): 21\n",
    "\n",
    "- This is a large dataset, great for training machine learning models ‚Äî but also requires careful preprocessing due to potential data quality issues.\n",
    "\n",
    "**üîπ 2. Target Variable Candidate**\n",
    "    \n",
    "- A strong candidate for prediction is likely \"Amount(in rupees)\" or \"Price (in rupees)\":\n",
    "\n",
    "- Amount(in rupees) is in text format (e.g., \"42 Lac\", \"1.40 Cr\", \"Call for Price\").\n",
    "\n",
    "- Price (in rupees) is numeric (float64) and usable for regression, but has ~17,665 missing values.\n",
    "\n",
    "‚û°Ô∏è We'll most likely use Price (in rupees) as the target, after cleaning or imputing missing prices.\n",
    "\n",
    "**üîπ 3. Presence of Text and Categorical Features**\n",
    "    \n",
    "- Many columns like Title, Description, location, Status, Transaction, Furnishing, facing, Society, etc., are textual/categorical.\n",
    "\n",
    "- These will need encoding (like LabelEncoding or OneHotEncoding) before feeding into ML models.\n",
    "\n",
    "**üîπ 4. Mixed-Type or Object-Type Numerical Features**\n",
    "    \n",
    "Some important columns that look numerical but are stored as object (string):\n",
    "\n",
    "- Carpet Area ‚Üí values like \"500 sqft\" need to be cleaned\n",
    "\n",
    "- Floor ‚Üí format like \"10 out of 11\" ‚Üí needs parsing\n",
    "\n",
    "- Balcony, Bathroom ‚Üí stored as object, but should be numeric\n",
    "\n",
    "‚û°Ô∏è These need to be converted to numeric properly before modeling.\n",
    "\n",
    "**üîπ 5. Severe Missing Values**\n",
    "\n",
    "Let‚Äôs break it down:\n",
    "\n",
    "| Column                    | Missing % | Comment                                             |\n",
    "| ------------------------- | --------- | --------------------------------------------------- |\n",
    "| `Description`             | \\~1.6%    | Okay to keep, not critical                          |\n",
    "| `Price`                   | \\~9.4%    | ‚ö†Ô∏è Important! Needs to be handled carefully         |\n",
    "| `Carpet Area`             | \\~43%     | High missing rate                                   |\n",
    "| `Society`                 | \\~58%     | May consider dropping if not useful                 |\n",
    "| `Car Parking`             | \\~55%     | Clean/encode carefully                              |\n",
    "| `Super Area`              | \\~57%     | Very high missing rate                              |\n",
    "| `Dimensions`, `Plot Area` | **100%**  | üí£ These are completely missing ‚Äî should be dropped |\n",
    "\n",
    "‚û°Ô∏è You'll need to drop fully-null columns and strategically fill/clean the others.\n",
    "\n",
    "**üîπ 6. Duplicate or Redundant Columns**\n",
    "    \n",
    "- Index column is just a row number ‚Äî we can drop it.\n",
    "\n",
    "- Title and Description contain free-text ‚Äî useful for NLP, but not for simple regression without preprocessing.\n",
    "\n",
    "**üîπ 7. Suspicious Values in \"Amount(in rupees)\"**\n",
    "                                                                    \n",
    "- This column contains values like:\n",
    "\n",
    "\"42 Lac\", \"1.40 Cr\", \"Call for Price\" ‚Üí stored as object\n",
    "\n",
    "- Not usable for regression unless cleaned and converted to numerical rupees\n",
    "\n",
    "### ‚úÖ Summary of Next Steps (after Insights):\n",
    "\n",
    "**Drop useless columns:**\n",
    "\n",
    "- Index, Dimensions, Plot Area\n",
    "\n",
    "**Handle missing values:**\n",
    "\n",
    "- Drop columns with all nulls\n",
    "\n",
    "-Fill others (median for numeric, mode for categorical)\n",
    "\n",
    "**Clean string/object columns:**\n",
    "\n",
    "- Parse Carpet Area, Floor, Amount(in rupees), etc.\n",
    "\n",
    "**Encode categorical variables**\n",
    "\n",
    "**Scale numeric features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5fb77-5e8a-478a-b396-e601ab79de71",
   "metadata": {},
   "source": [
    "## üî∑ Step 2: Data Preprocessing\n",
    "\n",
    "We'll divide it into mini-parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de51f4-f280-4d19-90c9-83e0bf74eadb",
   "metadata": {},
   "source": [
    "üîπ A. Drop Unnecessary or Useless Columns\n",
    "\n",
    "üîπ B. Handle Missing Values\n",
    "\n",
    "üîπ C. Clean Mixed-Type Object Columns (like Carpet Area, Floor, etc.)\n",
    "\n",
    "üîπ D. Encode Categorical Columns\n",
    "\n",
    "üîπ E. Scale Numerical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affc73f1-a014-4db6-8de4-26097eaeb28d",
   "metadata": {},
   "source": [
    "### A. Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7adeba73-9c94-4772-91a2-e96c7b2a63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop completely useless or fully missing columns\n",
    "df.drop([\"Index\", \"Dimensions\", \"Plot Area\"], axis=1, inplace=True)\n",
    "\n",
    "# Optional: Drop target rows with missing Price (important for supervised learning)\n",
    "df = df[df[\"Price (in rupees)\"].notnull()]\n",
    "\n",
    "# üîç What This Does:\n",
    "# Removes columns that are either identifiers (Index) or completely empty.\n",
    "# Drops rows where the target (Price) is missing, since we can‚Äôt train on them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e94e35-faa4-484b-94ff-31dde46ec54f",
   "metadata": {},
   "source": [
    "### B. Handle Missing Values (Cleanly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4f51d4-8dec-484e-8099-5434917c949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values after imputation\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1. Separate numerical and categorical columns\n",
    "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns #select_dtypes(...): Helps separate numeric and categorical columns.\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# 2. Fill missing values\n",
    "# üëâ For numerical columns: fill with median\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median()) #fillna(...).median(): Replaces nulls in numeric columns with median values to avoid the effect of outliers.\n",
    "\n",
    "# üëâ For categorical columns: fill with mode (most frequent value)\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0]) #df[col].mode()[0]: Fills nulls in text columns with the most common value (mode).\n",
    "\n",
    "# 3. Confirm no more missing values\n",
    "print(\"Missing Values after imputation\")\n",
    "print(df.isnull().sum().sum()) # .sum().sum(): Confirms that all missing values are handled (should be 0 if successful).\n",
    "\n",
    "# üîç What This Does:\n",
    "# Fills numerical nulls using median to avoid outlier distortion.\n",
    "# Fills categorical nulls using most frequent value (mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e2e9f2-7c12-4bb2-b321-3681f7f72bd8",
   "metadata": {},
   "source": [
    "### C. Clean Mixed-Type Object Columns\n",
    "\n",
    "Some object-type columns that should be numerical need to be cleaned:\n",
    "\n",
    "**üõ† Convert \"Carpet Area\" like \"1000 sqft\" ‚Üí numeric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36d02fa-5b97-4046-9890-0e8f2f8bd36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract only numbers\n",
    "df[\"Carpet Area\"] = df[\"Carpet Area\"].str.extract(r'(\\d+\\.?\\d*)')\n",
    "# \\d+\tOne or more digits (e.g., 3683)\n",
    "# \\.?\tAn optional decimal point\n",
    "# \\d*\tZero or more digits after the decimal\n",
    "# ( ... )\tCapturing group to extract matched number\n",
    "\n",
    "# Step 2: Convert the result to float\n",
    "df[\"Carpet Area\"] = pd.to_numeric(df[\"Carpet Area\"], errors=\"coerce\")\n",
    "\n",
    "print(df[\"Carpet Area\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd66bd-5289-4fe3-9594-abe592c9264c",
   "metadata": {},
   "source": [
    "**üõ† Convert \"Floor\" like \"10 out of 22\" ‚Üí Extract current floor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66e2e8b2-8b30-458b-8ddf-24652dd9ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Floor\"] = df[\"Floor\"].str.extract(r'(\\d+)').astype(float)\n",
    "# \\d+ ‚Üí Matches one or more digits\n",
    "# (\\d+) ‚Üí Captures those digits so .str.extract() can return them\n",
    "# .astype(float) ‚Üí Converts the result to float for numerical use\n",
    "\n",
    "# From each floor entry, extract the first number (if any), and convert it to a float number so we can use it as a numeric feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3b5be-3fd9-448a-949e-5f34b45adce2",
   "metadata": {},
   "source": [
    ".extract(r'(\\d+)')\tThis uses a regular expression (regex) to extract only the first number from the string.\n",
    "\n",
    "- üîπ \\d+ means: ‚Äúone or more digits‚Äù (like 10, 3, 1, etc.)\n",
    "\n",
    "- üîπ r'(\\d+)' is a raw string, which is a cleaner way to write regex in Python.\n",
    "\n",
    "üëâ So, it extracts just the current floor number ‚Äî for example:\n",
    "\n",
    "\"10 out of 22\" ‚Üí 10\n",
    "\n",
    "\"3 out of 10\" ‚Üí 3\n",
    "\n",
    "\"Ground out of 4\" ‚Üí NaN (no digits found)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd064b-b507-479d-90ad-8ac28b113fb7",
   "metadata": {},
   "source": [
    "**üõ† Convert \"Amount(in rupees)\" like \"1.4 Cr\", \"25 Lac\" ‚Üí rupees**\n",
    "\n",
    "*üí° Problem We‚Äôre Solving*\n",
    "\n",
    "\"Amount(in rupees)\" column has textual prices like:\n",
    "\n",
    "\"1.4 Cr\"\n",
    "\n",
    "\"98 Lac\"\n",
    "\n",
    "\"Call for Price\"\n",
    "\n",
    "\"42 Lac\"\n",
    "\n",
    "These are not directly usable for calculations or machine learning models ‚Äî so we clean and convert them to numeric rupee values (like 14000000, 9800000, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f360b0f9-7ebf-4ec8-9deb-621967b2feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def convert_to_rupees(value):\n",
    "    value = str(value).strip() \n",
    "    #Ensures the input is treated as a string, and .strip() removes any extra spaces from start or end.\n",
    "    if \"Cr\" in value:\n",
    "        return float(value.replace(\"Cr\", \"\").strip()) * 10000000\n",
    "        # Removes \"Cr\" from the string, Strips spaces, Converts the number (e.g. \"1.4\") to float ‚Üí 1.4, Multiplies by 1 crore = 1,00,00,000 ‚Üí returns 1.4 * 10000000 = 14000000\n",
    "    elif \"Lac\" in value:\n",
    "        return float(value.replace(\"Lac\", \"\").strip()) * 100000\n",
    "    elif value.lower() == \"call for price\":\n",
    "        return np.nan\n",
    "        # If the value is \"Call for Price\" (which means no price is disclosed), we return np.nan (missing value) so we can handle it later.\n",
    "    else:\n",
    "        try:\n",
    "            return float(value)\n",
    "        except:\n",
    "            return np.nan\n",
    "            # This handles edge cases like plain numeric strings (\"4200000\") ‚Äî it tries to convert them to float. If it fails (maybe string is something weird), it returns np.nan.\n",
    "\n",
    "#Apply Function to the Dataset\n",
    "df[\"Amount(in rupees)\"] = df[\"Amount(in rupees)\"].apply(convert_to_rupees) #This applies the function to each row of the \"Amount(in rupees)\" column ‚Äî converting everything to proper numbers.\n",
    "\n",
    "# Drop Failed Conversions\n",
    "df = df[df[\"Amount(in rupees)\"].notnull()] #After conversion, this keeps only rows where conversion succeeded ‚Äî drops rows where \"Call for Price\" or any invalid data caused the value to become NaN.\n",
    "\n",
    "print(df[\"Amount(in rupees)\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae26c07-be2b-41e0-90ae-6b9d6c7e62e9",
   "metadata": {},
   "source": [
    "### D. Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd4352-b787-4f9a-92c7-9dfb5185fe81",
   "metadata": {},
   "source": [
    "**üß† Why We Do This:**\n",
    "\n",
    "Most machine learning models (like Linear Regression, Random Forest, etc.) cannot handle text/categorical data directly. So we need to convert them into numbers.\n",
    "\n",
    "**üìå What We‚Äôll Do:**\n",
    "\n",
    "We‚Äôll use Label Encoding (for simplicity, since we are not using OneHotEncoding in this project). Label encoding assigns a unique integer to each unique category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a7dab77-bcca-4340-9403-2592890283c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Encoded Data:\n",
      "\n",
      "   Title  Description  Amount(in rupees)  location  Carpet Area  Status  \\\n",
      "0   3217         5020                712        67         1764       0   \n",
      "1  10105        24480               1532        67         1730       0   \n",
      "2  14467        56098                104        67         2108       0   \n",
      "4  14665        45436                156        67         1934       0   \n",
      "5   3424         9356                770        67            2       0   \n",
      "\n",
      "   Floor  Transaction  Furnishing  facing  overlooking  Society  Bathroom  \\\n",
      "0      1            3           2       0            6     8230         0   \n",
      "1     23            3           1       0            0     2119         2   \n",
      "2      1            3           2       0            0     8379         2   \n",
      "4     12            3           2       7            1     8671         2   \n",
      "5     11            3           2       0            1     9404         0   \n",
      "\n",
      "   Balcony  Car Parking  Ownership  Super Area  \n",
      "0        2            0          1         130  \n",
      "1        2            2          1         130  \n",
      "2        2            0          1         130  \n",
      "4        2            0          0         130  \n",
      "5        0            0          0        2497  \n",
      "Title                0\n",
      "Description          0\n",
      "Amount(in rupees)    0\n",
      "location             0\n",
      "Carpet Area          0\n",
      "Status               0\n",
      "Floor                0\n",
      "Transaction          0\n",
      "Furnishing           0\n",
      "facing               0\n",
      "overlooking          0\n",
      "Society              0\n",
      "Bathroom             0\n",
      "Balcony              0\n",
      "Car Parking          0\n",
      "Ownership            0\n",
      "Super Area           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder #LabelEncoder(): A scikit-learn tool to convert categorical values into integers (e.g., \"Yes\", \"No\" ‚Üí 1, 0).\n",
    "\n",
    "# 1. Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 2. Loop through all categorical columns and encode them\n",
    "for col in cat_cols: # for col in cat_cols:: We apply the encoding to each categorical column one by one.\n",
    "    df[col] = le.fit_transform(df[col].astype(str)) \n",
    "    #.astype(str): Ensures that even missing or numeric-looking categories are treated as strings (to avoid errors).\n",
    "    #df[col] = le.fit_transform(...): Replaces original text categories with encoded numbers.\n",
    "\n",
    "# 3. Confirm changes\n",
    "print(\"Sample of Encoded Data:\\n\")\n",
    "print(df[cat_cols].head())\n",
    "\n",
    "# 4. Check if any null values are left\n",
    "print(df[cat_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d1f6e-d9b2-4b0c-a8f1-6218a92f37b1",
   "metadata": {},
   "source": [
    "### E. Scale Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a28f79-d5b8-42f8-9c5a-80f22d997689",
   "metadata": {},
   "source": [
    "**üß† Why We Do This:**\n",
    "\n",
    "Machine Learning models ‚Äî especially those based on distance (like KNN, SVM) or gradient descent (like Linear Regression) ‚Äî often perform better when features are on a similar scale. Otherwise, columns with larger numeric ranges dominate.\n",
    "\n",
    "We‚Äôll use StandardScaler to standardize the features:\n",
    "\n",
    "- Centers data to mean = 0 and std deviation = 1.\n",
    "\n",
    "- Works well for many algorithms.\n",
    "\n",
    "**‚ö†Ô∏è Important Note:**\n",
    "            \n",
    "We will scale only numerical columns ‚Äî not encoded categorical ones, because the label-encoded values don‚Äôt have real numeric meaning (e.g., 0, 1, 2 for ‚Äúfurnishing‚Äù isn't an actual scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0908e82-51ed-4c3d-881b-45197b52f858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Scaled Numerical Columns:\n",
      "\n",
      "       Price (in rupees)\n",
      "count       1.698660e+05\n",
      "mean        5.354189e-18\n",
      "std         1.000003e+00\n",
      "min        -2.783891e-01\n",
      "25%        -1.206526e-01\n",
      "50%        -5.688985e-02\n",
      "75%         6.850649e-02\n",
      "max         2.456688e+02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler #StandardScaler(): A scaler that makes all numerical columns have mean 0 and standard deviation 1.\n",
    "\n",
    "# 1. Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Fit and transform only numerical columns\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols]) \n",
    "#scaler.fit_transform(...): Learns from the data and transforms it.\n",
    "#df[num_cols] = ...: Updates the original dataframe with the scaled values.\n",
    "\n",
    "# 3. Confirm changes\n",
    "print(\"Summary of Scaled Numerical Columns:\\n\")\n",
    "print(df[num_cols].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce62b7-bc2b-48bc-b15e-6d44ae370eaf",
   "metadata": {},
   "source": [
    "**Final Check: Confirm Dataset is Clean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9cff52-54d8-4324-9399-9b347f88740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any Missing Values Left?: 0\n",
      "\n",
      "Final Shape of Dataset: (169866, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Amount(in rupees)</th>\n",
       "      <th>Price (in rupees)</th>\n",
       "      <th>location</th>\n",
       "      <th>Carpet Area</th>\n",
       "      <th>Status</th>\n",
       "      <th>Floor</th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Furnishing</th>\n",
       "      <th>facing</th>\n",
       "      <th>overlooking</th>\n",
       "      <th>Society</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Balcony</th>\n",
       "      <th>Car Parking</th>\n",
       "      <th>Ownership</th>\n",
       "      <th>Super Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3217</td>\n",
       "      <td>5020</td>\n",
       "      <td>712</td>\n",
       "      <td>-0.058138</td>\n",
       "      <td>67</td>\n",
       "      <td>1764</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8230</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10105</td>\n",
       "      <td>24480</td>\n",
       "      <td>1532</td>\n",
       "      <td>0.228152</td>\n",
       "      <td>67</td>\n",
       "      <td>1730</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2119</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14467</td>\n",
       "      <td>56098</td>\n",
       "      <td>104</td>\n",
       "      <td>0.364010</td>\n",
       "      <td>67</td>\n",
       "      <td>2108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8379</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14665</td>\n",
       "      <td>45436</td>\n",
       "      <td>156</td>\n",
       "      <td>0.412612</td>\n",
       "      <td>67</td>\n",
       "      <td>1934</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8671</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3424</td>\n",
       "      <td>9356</td>\n",
       "      <td>770</td>\n",
       "      <td>-0.035452</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Title  Description  Amount(in rupees)  Price (in rupees)  location  \\\n",
       "0   3217         5020                712          -0.058138        67   \n",
       "1  10105        24480               1532           0.228152        67   \n",
       "2  14467        56098                104           0.364010        67   \n",
       "4  14665        45436                156           0.412612        67   \n",
       "5   3424         9356                770          -0.035452        67   \n",
       "\n",
       "   Carpet Area  Status  Floor  Transaction  Furnishing  facing  overlooking  \\\n",
       "0         1764       0      1            3           2       0            6   \n",
       "1         1730       0     23            3           1       0            0   \n",
       "2         2108       0      1            3           2       0            0   \n",
       "4         1934       0     12            3           2       7            1   \n",
       "5            2       0     11            3           2       0            1   \n",
       "\n",
       "   Society  Bathroom  Balcony  Car Parking  Ownership  Super Area  \n",
       "0     8230         0        2            0          1         130  \n",
       "1     2119         2        2            2          1         130  \n",
       "2     8379         2        2            0          1         130  \n",
       "4     8671         2        2            0          0         130  \n",
       "5     9404         0        0            0          0        2497  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Any Missing Values Left?:\", df.isnull().sum().sum())\n",
    "print(\"\\nFinal Shape of Dataset:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab16d6-1062-4e12-b0b1-953870fb16c0",
   "metadata": {},
   "source": [
    "## üî∑ Step 3: Split the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2996a-f9c6-44ba-aecc-7650180c1932",
   "metadata": {},
   "source": [
    "### ‚úÖ Use train_test_split() to divide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab617e4-53f4-4935-8bb4-108835e495ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate Features and Target\n",
    "# We'll predict \"Price (in rupees)\", so it's our target (y), and all other columns are features (X):\n",
    "y = df[\"Price (in rupees)\"] # target variable\n",
    "x = df.drop(\"Price (in rupees)\", axis=1)  # All other columns are features\n",
    "\n",
    "# plit the Dataset using train_test_split()\n",
    "# We'll split 80% for training and 20% fortesting. We'll also use random_state=42 to make the split reproducible.\n",
    "x_train , x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce4f75-4877-4cad-8f59-e8d3945ccfce",
   "metadata": {},
   "source": [
    "### ‚úÖ Understand the shape of training vs. test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9060ca4-f6bb-4829-aa6d-3a6194e8c4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Features (x_train): (135892, 17)\n",
      "Shape of Testing Features (x_test): (33974, 17)\n",
      "Shape of Training Labels (y_train): (135892,)\n",
      "Shape of Testing Labels (y_test): (33974,)\n"
     ]
    }
   ],
   "source": [
    "#Let's confirm how the data is split:\n",
    "print(\"Shape of Training Features (x_train):\", x_train.shape)\n",
    "print(\"Shape of Testing Features (x_test):\", x_test.shape)\n",
    "print(\"Shape of Training Labels (y_train):\", y_train.shape)\n",
    "print(\"Shape of Testing Labels (y_test):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d8499-0594-4583-bebb-90b579a174a8",
   "metadata": {},
   "source": [
    "### ‚úÖ Discuss what random_state does\n",
    "\n",
    "**üîç What is random_state?**\n",
    "\n",
    "- random_state controls the randomness of the train-test split.\n",
    "\n",
    "- When you set a fixed value (like 42), it ensures that every time you run the code, the split is the same.\n",
    "\n",
    "- Think of it like setting the same seed value.\n",
    "\n",
    "**üß† Example:**\n",
    "\n",
    "- If random_state=42, you and I will get the same train/test sets.\n",
    "\n",
    "- If you leave it out, the split will be random each time you run the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1310615f-824d-470b-a784-cf8941f31ac2",
   "metadata": {},
   "source": [
    "## üî∑ Step 4: Train the Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e5c1681-5864-45f4-8346-9a5190792c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression #LinearRegression is a simple yet powerful regression algorithm that finds the best-fitting straight line through the data to predict a continuous value.\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr_model = LinearRegression() #We create a LinearRegression object called lr_model. This is the model that will learn from the training data.\n",
    "\n",
    "# Fit the model on training data\n",
    "lr_model.fit(x_train, y_train)\n",
    "# .fit() tells the model to:\n",
    "# Look at the features (X_train)\n",
    "# Understand how they relate to the target (y_train)\n",
    "# Learn the best coefficients (weights) to make predictions\n",
    "\n",
    "# Predict house prices on test data\n",
    "y_pred = lr_model.predict(x_test) #.predict() uses the trained model to make predictions on unseen data (X_test). These predictions are stored in y_pred and represent the estimated house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe28154-5d68-4ba9-8754-a8a2b55eccd3",
   "metadata": {},
   "source": [
    "## üî∑ Step 5: Evaluate the Model\n",
    "\n",
    "| Metric       | What It Measures                              | Interpretation                                                        |\n",
    "| ------------ | --------------------------------------------- | --------------------------------------------------------------------- |\n",
    "| **MAE**      | Average error in same unit as target (rupees) | Lower is better. Tells how much you're wrong on average               |\n",
    "| **MSE**      | Squared error ‚Üí penalizes larger errors more  | Lower is better. Useful if you care about big errors                  |\n",
    "| **RMSE**     | Square root of MSE (brings back to rupees)    | Easier to understand. Should be close to MAE if errors are consistent |\n",
    "| **R¬≤ Score** | % of variance explained by the model          | Ranges from 0 to 1 (higher = better fit). 1 means perfect prediction  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b6e92b0-168d-4e95-bd9f-16d2cac1155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.12\n",
      "Mean Squared Error (MSE): 2.66\n",
      "Root Mean Squared Error (RMSE): 1.63\n",
      "R¬≤ Score: 0.0031\n"
     ]
    }
   ],
   "source": [
    "#1. Import Evaluation Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "# mean_absolute_error: Measures how far predictions are from actual values (on average).\n",
    "# mean_squared_error: Squares the errors (so large mistakes hurt more).\n",
    "# r2_score: Shows how well the model explains the variance (closer to 1 = better).\n",
    "# numpy (np): Needed to calculate Root of Mean Squared Error (RMSE).\n",
    "\n",
    "#2. Evaluate the Model\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# R¬≤ Score (Coefficient of Determination)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the Result\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7127ab-4696-492b-bb59-7baf6f16f473",
   "metadata": {},
   "source": [
    "**üîç What These Results Mean:**\n",
    "\n",
    "| Metric       | Value  | Interpretation                                                            |\n",
    "| ------------ | ------ | ------------------------------------------------------------------------- |\n",
    "| **MAE**      | 0.12   | Very low ‚Üí On average, the prediction is just ‚Çπ0.12 lakhs (\\~‚Çπ12,000) off |\n",
    "| **MSE**      | 2.66   | Error squared ‚Üí but harder to interpret directly                          |\n",
    "| **RMSE**     | 1.63   | Average prediction error is ‚Çπ1.63 lakhs (brings MSE back to rupee scale)  |\n",
    "| **R¬≤ Score** | 0.0031 | üö® Very low! The model is **barely better than guessing the average**     |\n",
    "\n",
    "**üí° Conclusion:**\n",
    "    \n",
    "- Your MAE and RMSE are reasonably low ‚Üí suggesting the actual predicted values aren't very far off.\n",
    "\n",
    "- But the R¬≤ score is almost zero, meaning: Your model explains less than 1% of the variance in price.\n",
    "\n",
    "This typically means:\n",
    "\n",
    "- There‚Äôs a lot of noise in the data,\n",
    "\n",
    "- Or some important features are missing or poorly preprocessed,\n",
    "\n",
    "- Or the model (Linear Regression) is too simple for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae962d-3d2b-474f-bee1-a11c427bd8c1",
   "metadata": {},
   "source": [
    "## üî∑ Step 6: Improve the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63a41f1-4640-4fb5-88c0-19364bf42be3",
   "metadata": {},
   "source": [
    "### Step 6.1: Try Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd28fe7f-12af-40ff-aa82-6e245fa872b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the model\n",
    "from sklearn.tree import DecisionTreeRegressor #This imports the Decision Tree regression model from scikit-learn.\n",
    "\n",
    "# 2. Initialize the model\n",
    "dt_model = DecisionTreeRegressor(random_state=42) #We create the model. The random_state=42 ensures reproducibility of the tree structure.\n",
    "\n",
    "# 3. Train the model on training data\n",
    "dt_model.fit(x_train, y_train) #This trains the model on the training data (X_train, y_train).\n",
    "\n",
    "# 4. Predict on the test set\n",
    "dt_preds = dt_model.predict(x_test) #The trained model now predicts house prices for the unseen test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba919757-3d9c-4a0e-850b-27349385ed4e",
   "metadata": {},
   "source": [
    "**Evaluate the Decision Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6494fb5b-2e20-4415-9b66-cb1256224b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor:\n",
      "Mean Absolute Error (MAE): 0.03\n",
      "Mean Squared Error (MSE): 2.92\n",
      "Root Mean Squared Error (RMSE): 1.71\n",
      "R¬≤ Score: -0.0961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate Decision Tree performance\n",
    "dt_mae = mean_absolute_error(y_test, dt_preds)\n",
    "dt_mse = mean_squared_error(y_test, dt_preds)\n",
    "dt_rmse = np.sqrt(dt_mse)\n",
    "dt_r2 = r2_score(y_test, dt_preds)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Decision Tree Regressor:\")\n",
    "print(f\"Mean Absolute Error (MAE): {dt_mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {dt_mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {dt_rmse:.2f}\")\n",
    "print(f\"R¬≤ Score: {dt_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1505a-475f-4bfc-83f6-2806a6315258",
   "metadata": {},
   "source": [
    "**üîç Comparison: Linear Regression vs. Decision Tree**\n",
    "\n",
    "| Metric   | Linear Regression | Decision Tree Regressor        |\n",
    "| -------- | ----------------- | ------------------------------ |\n",
    "| MAE      | 0.12              | **0.03** ‚úÖ *(lower is better)* |\n",
    "| MSE      | 2.66              | 2.92                           |\n",
    "| RMSE     | 1.63              | 1.71                           |\n",
    "| R¬≤ Score | 0.0031            | **-0.0961** ‚ùå *(worse)*        |\n",
    "\n",
    "**üìå Interpretation:**\n",
    "  \n",
    "- MAE improved significantly in Decision Tree ‚Üí good!\n",
    "\n",
    "- But R¬≤ Score is negative, which means the model is worse than a horizontal average line.\n",
    "\n",
    "- So, even though the tree fits very closely on training data, it's likely overfitting and not generalizing well to test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9b367-2512-41c6-a203-6efe84d1ebe2",
   "metadata": {},
   "source": [
    "### Step 6.2: Try Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68a78f1a-6986-4d8c-8c68-4f506b9d54de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the model\n",
    "from sklearn.ensemble import RandomForestRegressor #RandomForestRegressor: Builds multiple trees and averages their results to reduce overfitting.\n",
    "\n",
    "# 2. Initialize the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42) #n_estimators=100: Builds 100 trees. More trees = better performance, usually.\n",
    "\n",
    "# 3. Train the model\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# 4. Predict on the test set\n",
    "rf_preds = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6e04e-b9f6-49ea-ae55-5fb7551d971a",
   "metadata": {},
   "source": [
    "**Evaluate the Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f64856a-568e-4c0c-bd4c-e6386c3aadfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor:\n",
      "MAE: 0.03\n",
      "MSE: 2.66\n",
      "RMSE: 1.63\n",
      "R¬≤ Score: 0.0025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Then evaluate as usual\n",
    "rf_mae = mean_absolute_error(y_test, rf_preds)\n",
    "rf_mse = mean_squared_error(y_test, rf_preds)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "print(f\"Random Forest Regressor:\")\n",
    "print(f\"MAE: {rf_mae:.2f}\")\n",
    "print(f\"MSE: {rf_mse:.2f}\")\n",
    "print(f\"RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"R¬≤ Score: {rf_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dec888-adc6-4fc8-a619-275275fd26c8",
   "metadata": {},
   "source": [
    "**üîç Model Comparison (Based on Your Outputs)**\n",
    "\n",
    "| Metric                  | **Linear Regression** | **Decision Tree** | **Random Forest** |\n",
    "| ----------------------- | --------------------- | ----------------- | ----------------- |\n",
    "| **MAE** (‚Üì better)      | 0.12                  | **0.03**          | **0.03**          |\n",
    "| **MSE** (‚Üì better)      | 2.66                  | 2.92              | **2.66**          |\n",
    "| **RMSE** (‚Üì better)     | 1.63                  | 1.71              | **1.63**          |\n",
    "| **R¬≤ Score** (‚Üë better) | 0.0031                | **‚Äì0.0961 ‚ùå**     | **0.0025**        |\n",
    "\n",
    "**‚úÖ Interpretation**\n",
    "    \n",
    "- MAE: Lower is better ‚Üí Decision Tree and Random Forest are doing great here.\n",
    "\n",
    "- MSE & RMSE: Random Forest has slightly better performance than Decision Tree.\n",
    "\n",
    "- R¬≤ Score:\n",
    "\n",
    "-Measures how well your model explains the variance.\n",
    "\n",
    "-Linear Regression and Random Forest have positive but close to zero R¬≤ ‚Üí the model explains very little variance.\n",
    "\n",
    "-Decision Tree has negative R¬≤, which means it performs worse than just predicting the mean every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b80240-89f2-4d17-ba61-26841fa80f99",
   "metadata": {},
   "source": [
    "### Step 6.3: Try Regularization: Ridge, Lasso \n",
    "\n",
    "**üîò Try Regularization models ‚Äì Ridge and Lasso**\n",
    "\n",
    "These are:\n",
    "\n",
    "üîπ Still linear models like Linear Regression\n",
    "\n",
    "üîπ Used when the model overfits or when features are high-dimensional or correlated\n",
    "\n",
    "üîπ Can help improve generalization, but only when regular Linear Regression is struggling due to multicollinearity or overfitting\n",
    "\n",
    "Since the dataset has 187,531 rows and 21 columns, Ridge and Lasso are great to try ‚Äî they help control overfitting in large datasets and give you exposure to regularization techniques üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a566260d-914d-4ac9-bd30-3f7ae8c455b6",
   "metadata": {},
   "source": [
    "**üî∑ Let‚Äôs Start with: Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caeb391a-1190-4d15-bbf7-3447d61a4efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression:\n",
      "MAE: 0.12\n",
      "MSE: 2.66\n",
      "RMSE: 1.63\n",
      "R¬≤ Score: 0.0031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. Create a Ridge model with alpha (regularization strength)\n",
    "ridge_model = Ridge(alpha=1.0)  # alpha=1.0 is default \n",
    "#Ridge(alpha=1.0) Creates a Ridge Regression model. alpha controls how much regularization to apply (higher = more shrinkage).\n",
    "\n",
    "# 2. Train the model on training data\n",
    "ridge_model.fit(x_train, y_train)\n",
    "\n",
    "# 3. Predict on test data\n",
    "ridge_preds = ridge_model.predict(x_test)\n",
    "\n",
    "# 4. Evaluate performance\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_preds)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_preds)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "ridge_r2 = r2_score(y_test, ridge_preds)\n",
    "\n",
    "# 5. Print results\n",
    "print(\"Ridge Regression:\")\n",
    "print(f\"MAE: {ridge_mae:.2f}\")\n",
    "print(f\"MSE: {ridge_mse:.2f}\")\n",
    "print(f\"RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"R¬≤ Score: {ridge_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017e620-c1bf-45df-abb7-06ab43852c7e",
   "metadata": {},
   "source": [
    "*üîç Interpretation:*\n",
    "\n",
    "- MAE (0.12): On average, the model‚Äôs predictions are off by 0.12 units (in the same units as your target).\n",
    "\n",
    "- MSE/ RMSE (1.63): Error size is moderate; close to what we got from other models.\n",
    "\n",
    "- R¬≤ (0.0031): Very low‚Äîthis means the model is only able to explain ~0.3% of the variation in house prices.\n",
    "\n",
    "‚ö†Ô∏è This confirms that the data may be too noisy, or that important features are missing or not yet properly cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e857c-021c-44cf-9103-d9b80a0c7938",
   "metadata": {},
   "source": [
    "**üî∑ Lasso Regression**\n",
    "\n",
    "Just like Ridge, but with L1 regularization, which can also shrink some feature weights to zero (feature selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd9ace7b-938f-4133-8a50-1ccb92a6f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression:\n",
      "MAE: 0.13\n",
      "MSE: 2.66\n",
      "RMSE: 1.63\n",
      "R¬≤ Score: 0.0018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# 1. Create a Lasso model with alpha (regularization strength)\n",
    "lasso_model = Lasso(alpha=1.0) #Builds a Lasso regression model. L1 regularization shrinks some coefficients to 0, performing automatic feature selection.\n",
    "\n",
    "# 2. Train the model on training data\n",
    "lasso_model.fit(x_train, y_train)\n",
    "\n",
    "# 3. Predict on test data\n",
    "lasso_preds = lasso_model.predict(x_test)\n",
    "\n",
    "# 4. Evaluate performance\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_preds)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_preds)\n",
    "lasso_rmse = np.sqrt(lasso_mse)\n",
    "lasso_r2 = r2_score(y_test, lasso_preds)\n",
    "\n",
    "# 5. Print results\n",
    "print(\"Lasso Regression:\")\n",
    "print(f\"MAE: {lasso_mae:.2f}\")\n",
    "print(f\"MSE: {lasso_mse:.2f}\")\n",
    "print(f\"RMSE: {lasso_rmse:.2f}\")\n",
    "print(f\"R¬≤ Score: {lasso_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4871074-a00b-482e-b063-ffed2087c198",
   "metadata": {},
   "source": [
    "### Step 6.4: Compare model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654062e-8818-4ff6-94e0-1d4ca6313202",
   "metadata": {},
   "source": [
    "**üìä Regression Model Comparison Table**\n",
    "\n",
    "| Model                       | MAE  | MSE  | RMSE | R¬≤ Score      |\n",
    "| --------------------------- | ---- | ---- | ---- | ------------- |\n",
    "| **Linear Regression**       | 0.13 | 2.66 | 1.63 | 0.0024        |\n",
    "| **Ridge Regression**        | 0.13 | 2.66 | 1.63 | 0.0024        |\n",
    "| **Lasso Regression**        | 0.13 | 2.66 | 1.63 | 0.0018        |\n",
    "| **Decision Tree Regressor** | 0.03 | 2.92 | 1.71 | **-0.0961** ‚ùå |\n",
    "| **Random Forest Regressor** | 0.03 | 2.66 | 1.63 | **0.0025** ‚úÖ  |\n",
    "\n",
    "**üß† Interpretation & Insights**\n",
    "    \n",
    "*‚úÖ Best Overall (R¬≤ Score)*\n",
    "    \n",
    "- Random Forest gave the highest R¬≤ Score (0.0025) ‚Äî even though it‚Äôs still very low, it slightly outperformed others.\n",
    "\n",
    "*ü§î What does this mean?*\n",
    "\n",
    "-All models are giving very similar performance, and R¬≤ is near 0, which indicates:\n",
    "\n",
    "- Your current features do not explain the target (price per sqft) very well.\n",
    "\n",
    "- Possibly important features like location quality, amenities, flat age, etc., are missing or not fully cleaned.\n",
    "\n",
    "*‚ö†Ô∏è Decision Tree had:*\n",
    "    \n",
    "- Low MAE but negative R¬≤, meaning it overfitted on the training data and did poorly on test data.\n",
    "\n",
    "üìå Final Notes\n",
    "\n",
    "The models are working, but the data's predictive power is weak ‚Äî that‚Äôs common in real estate datasets that aren‚Äôt cleaned deeply or lack powerful features.\n",
    "\n",
    "Further improvement needs:\n",
    "\n",
    "Feature engineering (e.g., extract BHK count from title)\n",
    "\n",
    "Grouping locations into zones\n",
    "\n",
    "Dropping more noisy columns (e.g., Society, Description, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd607efe-86c2-49d4-8f78-cf6ed9a54415",
   "metadata": {},
   "source": [
    "**‚úÖ Final Ranking (based on this data):**\n",
    "\n",
    "ü•á Random Forest\n",
    "\n",
    "ü•à Linear / Ridge\n",
    "\n",
    "ü•â Lasso\n",
    "\n",
    "‚ùå Decision Tree (Overfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07fde10-75ea-4060-8363-a37b4cd664d6",
   "metadata": {},
   "source": [
    "## üî∑ Step 7: Wrap Up\n",
    "\n",
    "### Save the Best Model\n",
    "\n",
    "Make a nice GitHub repo and README\n",
    "\n",
    "Post progress on LinkedIn (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccf2c404-7c5f-4115-ae20-1f42eec72cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved as random_forest_regressor_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib # joblib is great for saving ML models\n",
    "\n",
    "# Save the best model (Random Forest Regressor) #joblib.dump(...): Saves your trained model to a .pkl file #Later, you can load it using joblib.load(\"random_forest_regressor_model.pkl\")\n",
    "joblib.dump(rf_model, \"random_forest_regressor_model.pkl\")\n",
    "print(\"model saved as random_forest_regressor_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41101321-4b10-457f-b010-9457868255c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
